{
  "trace_data": {
    "id": "1f06ddb4-f546-6d0e-ae5f-8eeafd1895a6",
    "name": "trading_agents",
    "run_type": "chain",
    "status": "error",
    "start_time": "2025-07-31T06:55:15.324127",
    "end_time": "2025-07-31T06:56:11.860620",
    "inputs": {
      "company_of_interest": "AAOI",
      "trade_date": "2025-07-30"
    },
    "outputs": null,
    "error": "RemoteProtocolError('peer closed connection without sending complete message body (incomplete chunked read)')Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 342, in __aiter__\n    raise exc\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 334, in __aiter__\n    async for chunk in self._connection._receive_response_body(**kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 203, in _receive_response_body\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 213, in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\n\nhttpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\n\nThe above exception was the direct cause of the following exception:\n\n\n\nTraceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 2768, in astream\n    async for _ in runner.atick(\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/fundamentals_analyst.py\", line 150, in fundamentals_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 932, in agenerate\n    raise exceptions[0]\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 270, in __aiter__\n    with map_httpcore_exceptions():\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\n\nhttpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\nDuring task with name 'fundamentals_analyst' and id 'af8022c6-c1e6-5e81-ee39-f7558a3dd658'",
    "total_tokens": 6660,
    "prompt_tokens": 6660,
    "completion_tokens": 0,
    "child_runs": [
      {
        "id": "840b1591-aa1b-4be9-9793-1906b8b2b749",
        "name": "social_analyst",
        "run_type": "chain",
        "status": "error",
        "start_time": "2025-07-31T06:55:56.051569",
        "end_time": "2025-07-31T06:56:11.857435",
        "total_tokens": 948,
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/social_media_analyst.py\", line 137, in social_media_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "id": "e5c6570d-8ee1-4108-8de4-a214da977570",
        "name": "news_analyst",
        "run_type": "chain",
        "status": "error",
        "start_time": "2025-07-31T06:55:56.050936",
        "end_time": "2025-07-31T06:56:11.856575",
        "total_tokens": 1038,
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/news_analyst.py\", line 134, in news_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "id": "bcc8a8fd-0bcd-4516-b3c2-867ec61b3dd1",
        "name": "market_analyst",
        "run_type": "chain",
        "status": "error",
        "start_time": "2025-07-31T06:55:56.050236",
        "end_time": "2025-07-31T06:56:11.855697",
        "total_tokens": 872,
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/market_analyst.py\", line 142, in market_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "id": "b2c4514d-53f7-4e8a-9b90-b80d97c6fca6",
        "name": "fundamentals_analyst",
        "run_type": "chain",
        "status": "error",
        "start_time": "2025-07-31T06:55:56.049075",
        "end_time": "2025-07-31T06:56:11.848931",
        "total_tokens": 0,
        "error": "RemoteProtocolError('peer closed connection without sending complete message body (incomplete chunked read)')Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 342, in __aiter__\n    raise exc\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 334, in __aiter__\n    async for chunk in self._connection._receive_response_body(**kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 203, in _receive_response_body\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 213, in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\n\nhttpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\n\nThe above exception was the direct cause of the following exception:\n\n\n\nTraceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/fundamentals_analyst.py\", line 150, in fundamentals_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 932, in agenerate\n    raise exceptions[0]\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 270, in __aiter__\n    with map_httpcore_exceptions():\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\n\nhttpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"
      },
      {
        "id": "3f5d134c-ac59-428e-812c-296a433591a4",
        "name": "social_tools",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:27.126143",
        "end_time": "2025-07-31T06:55:32.736478",
        "total_tokens": 0,
        "error": null
      },
      {
        "id": "c9cd0535-a976-4554-b677-116d10b03bb7",
        "name": "news_tools",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:27.125853",
        "end_time": "2025-07-31T06:55:56.038966",
        "total_tokens": 0,
        "error": null
      },
      {
        "id": "af531764-a4d0-422e-8a36-8323c8634f70",
        "name": "market_tools",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:27.125587",
        "end_time": "2025-07-31T06:55:34.994906",
        "total_tokens": 0,
        "error": null
      },
      {
        "id": "eff9f9c6-42ca-420f-9078-38fbac63cb6b",
        "name": "fundamentals_tools",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:27.125242",
        "end_time": "2025-07-31T06:55:33.995163",
        "total_tokens": 0,
        "error": null
      },
      {
        "id": "e9d5e917-a861-49b4-aa80-d50c4664f342",
        "name": "social_analyst",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:15.374349",
        "end_time": "2025-07-31T06:55:17.651027",
        "total_tokens": 944,
        "error": null
      },
      {
        "id": "2e5d7de5-f612-42d5-b448-98f4d7218a0d",
        "name": "news_analyst",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:15.374197",
        "end_time": "2025-07-31T06:55:17.346655",
        "total_tokens": 1034,
        "error": null
      },
      {
        "id": "fbf59334-4763-4a8a-ba41-bfb9c49eda9c",
        "name": "market_analyst",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:15.374039",
        "end_time": "2025-07-31T06:55:27.046671",
        "total_tokens": 868,
        "error": null
      },
      {
        "id": "30be8961-ec38-465e-9083-875748a4e910",
        "name": "fundamentals_analyst",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:15.373825",
        "end_time": "2025-07-31T06:55:16.768926",
        "total_tokens": 956,
        "error": null
      },
      {
        "id": "dd7b0f91-5780-46b3-8be2-62b84d723d9c",
        "name": "dispatcher",
        "run_type": "chain",
        "status": "success",
        "start_time": "2025-07-31T06:55:15.368106",
        "end_time": "2025-07-31T06:55:15.371158",
        "total_tokens": 0,
        "error": null
      }
    ],
    "extra": {
      "metadata": {
        "created_by": "system",
        "graph_id": "trading_agents",
        "assistant_id": "b07ca2df-7906-5911-85ed-209158e01746",
        "from_studio": true,
        "LANGGRAPH_API_URL": "http://127.0.0.1:2024",
        "thread_id": "925a0543-7899-45d7-9751-3dee250354c6",
        "x-auth-scheme": "langsmith",
        "x-user-id": "86432c3b-ea5d-49ab-8912-f22cc8317bcf",
        "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "x-request-id": "7408a552-d5c2-4fd1-98b0-44571385c689",
        "langgraph_auth_user_id": "",
        "langgraph_request_id": "7408a552-d5c2-4fd1-98b0-44571385c689",
        "run_id": "1f06ddb4-f546-6d0e-ae5f-8eeafd1895a6",
        "user_id": "",
        "run_attempt": 1,
        "langgraph_version": "0.5.3",
        "langgraph_api_version": "0.2.98",
        "langgraph_plan": "developer",
        "langgraph_host": "self-hosted",
        "langgraph_api_url": "http://127.0.0.1:2024",
        "LANGSMITH_LANGGRAPH_API_VARIANT": "local_dev",
        "LANGSMITH_PROJECT": "trading-agent-graph",
        "ls_run_depth": 0
      },
      "runtime": {
        "sdk": "langsmith-py",
        "sdk_version": "0.4.8",
        "library": "langchain-core",
        "platform": "macOS-15.5-arm64-arm-64bit",
        "runtime": "python",
        "py_implementation": "CPython",
        "runtime_version": "3.11.12",
        "langchain_version": "0.3.26",
        "langchain_core_version": "0.3.69",
        "library_version": "0.3.69"
      }
    }
  },
  "analysis": {
    "trace_id": "1f06ddb4-f546-6d0e-ae5f-8eeafd1895a6",
    "summary": {
      "name": "trading_agents",
      "status": "error",
      "total_runs": 14,
      "run_types": {
        "chain": 13
      },
      "duration_seconds": 56.536493,
      "has_errors": true
    },
    "performance_metrics": {
      "total_tokens": 6660,
      "prompt_tokens": 6660,
      "completion_tokens": 0,
      "child_run_count": 13,
      "success_rate": 64.28571428571429
    },
    "error_analysis": [
      {
        "run_id": "1f06ddb4-f546-6d0e-ae5f-8eeafd1895a6",
        "run_name": "trading_agents",
        "error": "RemoteProtocolError('peer closed connection without sending complete message body (incomplete chunked read)')Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 342, in __aiter__\n    raise exc\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 334, in __aiter__\n    async for chunk in self._connection._receive_response_body(**kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 203, in _receive_response_body\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 213, in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\n\nhttpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\n\nThe above exception was the direct cause of the following exception:\n\n\n\nTraceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 2768, in astream\n    async for _ in runner.atick(\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/fundamentals_analyst.py\", line 150, in fundamentals_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 932, in agenerate\n    raise exceptions[0]\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 270, in __aiter__\n    with map_httpcore_exceptions():\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\n\nhttpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\nDuring task with name 'fundamentals_analyst' and id 'af8022c6-c1e6-5e81-ee39-f7558a3dd658'"
      },
      {
        "run_id": "840b1591-aa1b-4be9-9793-1906b8b2b749",
        "run_name": "social_analyst",
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/social_media_analyst.py\", line 137, in social_media_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "run_id": "e5c6570d-8ee1-4108-8de4-a214da977570",
        "run_name": "news_analyst",
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/news_analyst.py\", line 134, in news_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "run_id": "bcc8a8fd-0bcd-4516-b3c2-867ec61b3dd1",
        "run_name": "market_analyst",
        "error": "CancelledError(<object object at 0x11db1a930>)Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/market_analyst.py\", line 142, in market_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 894, in agenerate\n    results = await asyncio.gather(\n              ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 341, in __aiter__\n    await self.aclose()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 348, in aclose\n    await self._connection._response_closed()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 239, in _response_closed\n    async with self._state_lock:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_synchronization.py\", line 77, in __aenter__\n    await self._anyio_lock.acquire()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 1799, in acquire\n    await AsyncIOBackend.cancel_shielded_checkpoint()\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2350, in cancel_shielded_checkpoint\n    await sleep(0)\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 640, in sleep\n    await __sleep0()\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", line 634, in __sleep0\n    yield\n\n\nasyncio.exceptions.CancelledError: <object object at 0x11db1a930>"
      },
      {
        "run_id": "b2c4514d-53f7-4e8a-9b90-b80d97c6fca6",
        "run_name": "fundamentals_analyst",
        "error": "RemoteProtocolError('peer closed connection without sending complete message body (incomplete chunked read)')Traceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 271, in __aiter__\n    async for part in self._httpcore_stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 407, in __aiter__\n    raise exc from None\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 403, in __aiter__\n    async for part in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 342, in __aiter__\n    raise exc\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 334, in __aiter__\n    async for chunk in self._connection._receive_response_body(**kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 203, in _receive_response_body\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 213, in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\n\nhttpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n\n\nThe above exception was the direct cause of the following exception:\n\n\n\nTraceback (most recent call last):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 672, in ainvoke\n    input = await asyncio.create_task(\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 440, in ainvoke\n    ret = await self.afunc(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/utils/debug_logging.py\", line 116, in wrapper\n    result = await func(state, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/Users/bytedance/Documents/TradingAgents/trading-graph-server/src/agent/analysts/fundamentals_analyst.py\", line 150, in fundamentals_analyst_node\n    result = await chain.ainvoke(messages)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3088, in ainvoke\n    input_ = await coro_with_context(part(), context, create_task=True)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5447, in ainvoke\n    return await self.bound.ainvoke(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 400, in ainvoke\n    llm_result = await self.agenerate_prompt(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 974, in agenerate_prompt\n    return await self.agenerate(\n           ^^^^^^^^^^^^^^^^^^^^^\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 932, in agenerate\n    raise exceptions[0]\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1089, in _agenerate_with_cache\n    async for chunk in self._astream(messages, stop=stop, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 2709, in _astream\n    async for chunk in super()._astream(*args, **kwargs):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1281, in _astream\n    async for chunk in response:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 152, in __aiter__\n    async for item in self._iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 165, in __stream__\n    async for sse in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 156, in _iter_events\n    async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 307, in aiter_bytes\n    async for chunk in self._aiter_chunks(iterator):\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/openai/_streaming.py\", line 318, in _aiter_chunks\n    async for chunk in iterator:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 997, in aiter_bytes\n    async for raw_bytes in self.aiter_raw():\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_models.py\", line 1055, in aiter_raw\n    async for raw_stream_bytes in self.stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py\", line 176, in __aiter__\n    async for chunk in self._stream:\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 270, in __aiter__\n    with map_httpcore_exceptions():\n\n\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n\n\n  File \"/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\n\nhttpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"
      }
    ],
    "tool_usage": {
      "total_tool_calls": 0,
      "unique_tools": 0,
      "tool_calls": {},
      "tool_errors": {},
      "tool_success_rate": 100.0
    },
    "recommendations": [
      "\ud83d\udea8 Fix 5 errors found in the trace",
      "\u26a0\ufe0f Improve success rate (currently 64.3%)"
    ],
    "timestamp": "2025-07-31T00:01:47.437492"
  }
}