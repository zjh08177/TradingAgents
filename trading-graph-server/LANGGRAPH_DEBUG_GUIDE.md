# ğŸ› **LangGraph Local Debug Guide**

## ğŸ“‹ **Overview**

This guide provides comprehensive instructions for debugging LangGraph projects locally in the terminal. Based on successful debugging of the TradingAgents graph, these techniques can help identify and resolve common async, state management, and execution issues.

## ğŸ› ï¸ **Prerequisites**

### Required Tools
- **Python 3.8+** with virtual environment
- **LangGraph CLI**: `pip install langgraph-cli`
- **Environment Variables**: API keys configured in `.env`
- **Terminal Access**: Command-line interface

### Required API Keys
```bash
# In your .env file
OPENAI_API_KEY=sk-your-key-here
FINNHUB_API_KEY=your-finnhub-key    # Optional
SERPER_API_KEY=your-serper-key      # Optional
```

---

## âš¡ **Quick Start: One-Command Debug**

For the fastest debugging experience, use our comprehensive debug script:

```bash
cd trading-graph-server
./debug_local.sh
```

This script will:
- âœ… Verify your environment
- âœ… Test all imports and dependencies
- âœ… Run comprehensive debug tests
- âœ… Analyze graph structure
- âœ… Generate detailed debug report
- âœ… Set up logging for issue identification

---

## ğŸ”§ **Manual Debug Process**

### **Step 1: Enable Debug Environment**

```bash
cd trading-graph-server

# Essential debug settings
export PYTHONPATH=/Users/bytedance/Documents/TradingAgents/trading-graph-server/src:$PYTHONPATH
export LANGCHAIN_TRACING_V2=false
export LANGGRAPH_DEBUG=true
export PYTHON_LOG_LEVEL=DEBUG

# Load your environment
source venv/bin/activate
source .env
```

### **Verify Environment Setup**
```bash
# Check Python path
echo $PYTHONPATH

# Verify API keys (without exposing them)
python -c "import os; print('âœ… OpenAI key:', 'sk-' in str(os.getenv('OPENAI_API_KEY', '')))"
```

---

## ğŸ” **Advanced Logging System**

### **Node-Level Debug Logging**

All graph nodes now include comprehensive debug logging that captures:

#### **ğŸ“‹ What Gets Logged:**
- **Node Start/End**: Exact timing and execution flow
- **Input State**: Complete state summary with safe size limits
- **Output Results**: Detailed output analysis
- **Execution Time**: Performance monitoring
- **Error Details**: Full tracebacks with state at error
- **LLM Interactions**: Prompt/response lengths and timing
- **Data Fetches**: API calls, query details, and results
- **Memory Operations**: Query patterns and result counts

#### **ğŸ¯ Debug Decorator Usage:**

```python
from agent.utils.debug_logging import debug_node, log_llm_interaction, log_data_fetch

@debug_node("My_Node_Name")
async def my_node(state):
    # Your node logic here
    return result
```

#### **ğŸ“Š Log Output Example:**
```
================================================================================
ğŸš€ NODE START: Trader
ğŸ“‹ Node ID: Trader_1704127234567
â° Start Time: 2024-01-01T15:20:34.567890
================================================================================
ğŸ“¥ INPUT STATE SUMMARY:
   ğŸ“Š Total Keys: 8
   ğŸ”‘ Available Keys: ['company_of_interest', 'market_report', 'sentiment_report', ...]
   ğŸ“ company_of_interest: String(4 chars): TSLA
   ğŸ“ market_report: String(1247 chars): Technical analysis shows...
   ğŸ“ sentiment_report: String(856 chars): Social sentiment is...

âš¡ EXECUTING: Trader

ğŸ§  MEMORY GET: Technical analysis shows TSLA has strong...
ğŸ“Š Results Count: 2

ğŸ¤– LLM CALL: trader_llm
ğŸ“ Prompt Length: 1456 chars
ğŸ“¤ Response Length: 234 chars
â±ï¸  LLM Time: 2.345 seconds

âœ… NODE SUCCESS: Trader
â±ï¸  Execution Time: 3.678 seconds
ğŸ“¤ OUTPUT SUMMARY:
   ğŸ“Š Output Keys: 3
   ğŸ”‘ Result Keys: ['messages', 'trader_investment_plan', 'sender']
   ğŸ“ trader_investment_plan: String(234 chars): Based on comprehensive analysis...

================================================================================
ğŸ NODE COMPLETE: Trader
================================================================================
```

#### **ğŸ’¥ Error Logging Example:**
```
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
ğŸ’¥ NODE ERROR: Market_Analyst
ğŸ“‹ Node ID: Market_Analyst_1704127234567
â±ï¸  Failed After: 1.234 seconds
âŒ Error Type: KeyError
ğŸ’¬ Error Message: 'sentiment_report'
ğŸ“ Error Location: market_analyst in agent.analysts.market_analyst
ğŸ” Full Traceback:
   Traceback (most recent call last):
     File "agent/analysts/market_analyst.py", line 45, in market_analyst
       sentiment = state["sentiment_report"]
   KeyError: 'sentiment_report'

ğŸ—‚ï¸  STATE AT ERROR:
   ğŸ“ company_of_interest: String(4 chars): TSLA
   ğŸ“ trade_date: String(10 chars): 2024-01-15
   ğŸ“ market_report: String(1247 chars): Technical analysis...
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
```

---

## ğŸ§ª **Debug Test Framework**

### **Comprehensive Debug Test**

Run the enhanced debug test:

```bash
python debug_test.py
```

This test covers:
1. **Environment Verification** - API keys, paths
2. **Import Testing** - All modules and dependencies  
3. **LLM Connectivity** - Basic LLM functionality
4. **Memory System** - Memory initialization
5. **Graph Compilation** - Node/edge verification
6. **Debug Logging** - Decorator functionality
7. **Quick Execution** - End-to-end graph test

### **Expected Success Output:**
```
ğŸš€ Starting enhanced debug test of trading graph
ğŸ”‘ Testing environment...
âœ… OpenAI API key found
ğŸ“¦ Testing imports...
âœ… All imports successful
ğŸ¤– Testing LLM creation...
âœ… LLM test result: LLM working
ğŸ’¾ Testing memory system...
âœ… Memory system created successfully
ğŸ—ï¸ Testing graph compilation...
âœ… Graph compiled with 21 nodes
ğŸ” Testing debug logging...
âœ… Debug logging test: {'test': 'success', 'debug_working': True}
âš¡ Testing quick graph execution...
âœ… Quick graph execution completed in 45.32 seconds
ğŸ“Š Final decision: HOLD

ğŸ‰ ENHANCED DEBUG TEST PASSED - Graph is working correctly!
```

---

## ğŸš€ **Server Debug Mode**

### **Start Server with Full Logging**
```bash
# Option 1: Production-ready (no --allow-blocking)
langgraph dev --port 8123 --no-browser

# Option 2: Development mode (if needed)
langgraph dev --port 8123 --allow-blocking --no-browser
```

### **Monitor Debug Logs in Real-Time**
```bash
# Watch graph debug logs
tail -f graph_debug.log

# Watch all debug output
tail -f debug_logs/debug_session_*.log
```

### **Test Server Endpoints**
```bash
# Health check
curl -s http://127.0.0.1:8123/assistants && echo "âœ… Server responding"

# Create assistant
curl -X POST http://127.0.0.1:8123/assistants \
  -H "Content-Type: application/json" \
  -d '{"graph_id": "trading_agents"}'

# Create thread for testing
curl -X POST http://127.0.0.1:8123/threads \
  -H "Content-Type: application/json" \
  -d '{}'
```

---

## ğŸ› **Issue Identification & Solutions**

### **ğŸ” How to Identify Issues with Debug Logs**

#### **1. Node Execution Issues**
**Look for:** Missing `ğŸ NODE COMPLETE` messages
**Indicates:** Node crashed or hung
**Debug:** Check the last `âš¡ EXECUTING` message and error logs

#### **2. State Access Problems**  
**Look for:** `KeyError` in state access
**Indicates:** Missing state keys or improper initialization
**Debug:** Check `ğŸ“¥ INPUT STATE SUMMARY` for available keys

#### **3. LLM Issues**
**Look for:** Long `â±ï¸ LLM Time` or LLM errors
**Indicates:** API issues, prompt problems, or network delays
**Debug:** Check `ğŸ¤– LLM CALL` logs for prompt/response details

#### **4. Data Fetch Problems**
**Look for:** `ğŸ“¡ DATA FETCH` errors or zero results
**Indicates:** API key issues, network problems, or rate limiting
**Debug:** Check data source logs and API responses

#### **5. Memory System Issues**
**Look for:** `ğŸ§  MEMORY` operation failures
**Indicates:** Memory initialization or query problems  
**Debug:** Check memory logs and query patterns

### **Common Issues & Solutions**

#### **Issue 1: `CancelledError()` in Async Context**
**Symptoms in Logs:**
```
ğŸ’¥ NODE ERROR: Research_Manager
âŒ Error Type: CancelledError
ğŸ’¬ Error Message: 
```

**Solution:**
```python
# âŒ Wrong - Sync operations
import time
import requests
result = llm.invoke(messages)
time.sleep(1)

# âœ… Correct - Async operations  
import asyncio
import httpx
result = await llm.ainvoke(messages)
await asyncio.sleep(1)
```

#### **Issue 2: `KeyError` in State Access**
**Symptoms in Logs:**
```
ğŸ’¥ NODE ERROR: Trader
âŒ Error Type: KeyError
ğŸ’¬ Error Message: 'sentiment_report'
ğŸ—‚ï¸  STATE AT ERROR:
   ğŸ“ company_of_interest: String(4 chars): TSLA
   ğŸ“ market_report: String(1247 chars): Technical analysis...
   # No sentiment_report key!
```

**Solution:**
```python
# âŒ Wrong - Direct access
sentiment_report = state["sentiment_report"]

# âœ… Correct - Safe access with defaults
sentiment_report = state.get("sentiment_report", "")
```

#### **Issue 3: LLM Message Format Errors**
**Symptoms in Logs:**
```
ğŸ’¥ NODE ERROR: News_Analyst
âŒ Error Type: AttributeError
ğŸ’¬ Error Message: 'coroutine' object has no attribute 'get'
```

**Solution:**
```python
# âŒ Wrong - Raw string to LLM
result = await llm.ainvoke(prompt_string)

# âœ… Correct - Proper message format
messages = [{"role": "user", "content": prompt_string}]
result = await llm.ainvoke(messages)
```

---

## ğŸ“Š **Debug Report Analysis**

### **Generated Debug Files**

After running `./debug_local.sh`, you'll get:

```
debug_logs/
â”œâ”€â”€ debug_session_20240115_142030.log    # Full debug session
â”œâ”€â”€ graph_debug_20240115_142030.log      # Graph execution logs  
â””â”€â”€ debug_report_20240115_142030.md      # Comprehensive report
```

### **Reading the Debug Report**

The generated report includes:
- **Environment Status** - Python, paths, keys
- **Test Results** - All debug test outcomes
- **Next Steps** - Specific commands to run
- **Debug Commands** - Useful debugging commands

### **Key Sections to Check:**

1. **Environment Status** - Ensure all prerequisites met
2. **Test Results** - Identify which tests failed
3. **Graph Analysis** - Verify node count and structure
4. **Debug Commands** - Use for ongoing debugging

---

## ğŸ¯ **Advanced Debugging Techniques**

### **Real-Time Log Monitoring**

```bash
# Monitor all debug activity
tail -f debug_logs/debug_session_*.log

# Monitor specific node execution
grep "NODE START\|NODE ERROR" debug_logs/graph_debug_*.log

# Monitor LLM interactions
grep "LLM CALL" debug_logs/graph_debug_*.log

# Monitor data fetches
grep "DATA FETCH" debug_logs/graph_debug_*.log
```

### **Performance Analysis**

```bash
# Find slowest nodes
grep "Execution Time" debug_logs/graph_debug_*.log | sort -k5 -nr

# Find LLM performance issues
grep "LLM Time" debug_logs/graph_debug_*.log | sort -k5 -nr

# Find data fetch delays
grep "Fetch Time" debug_logs/graph_debug_*.log | sort -k6 -nr
```

### **Error Pattern Analysis**

```bash
# Find all errors
grep "NODE ERROR" debug_logs/graph_debug_*.log

# Find specific error types
grep "KeyError\|CancelledError\|AttributeError" debug_logs/debug_session_*.log

# Find state-related issues
grep "STATE AT ERROR" -A 10 debug_logs/graph_debug_*.log
```

---

## âœ… **Verification Checklist**

### **ğŸ”§ Environment Setup**
- [ ] Virtual environment activated
- [ ] API keys configured in `.env`
- [ ] PYTHONPATH set correctly
- [ ] Debug environment variables set
- [ ] All dependencies installed

### **ğŸ“ Code Quality**
- [ ] All nodes have `@debug_node()` decorators
- [ ] All functions are `async def` where needed
- [ ] All LLM calls use `await llm.ainvoke()`
- [ ] All HTTP calls use `httpx` instead of `requests`
- [ ] All `time.sleep()` replaced with `await asyncio.sleep()`
- [ ] All state access uses `.get()` with defaults

### **ğŸ§ª Execution Tests**
- [ ] `./debug_local.sh` passes all phases
- [ ] Graph compiles without errors
- [ ] Server starts without `--allow-blocking`
- [ ] Full execution completes successfully
- [ ] No `CancelledError` or `KeyError` exceptions
- [ ] Debug logs show complete node execution

### **ğŸ“Š Integration Tests**
- [ ] LangGraph Studio shows all nodes
- [ ] API endpoints respond correctly
- [ ] State flows properly between nodes
- [ ] Final decision is generated
- [ ] All logging captures expected detail

---

## ğŸš€ **Production Deployment**

Once debugging is complete:

```bash
# Start production server (no --allow-blocking needed)
langgraph dev --port 8123

# Verify production readiness
curl -X POST http://127.0.0.1:8123/assistants \
  -H "Content-Type: application/json" \
  -d '{"graph_id": "trading_agents"}'
```

---

## ğŸ“š **Debug Resources**

### **ğŸ› ï¸ Debug Tools**
- **LangGraph Studio**: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123`
- **Debug Script**: `./debug_local.sh`
- **Debug Logs**: `tail -f debug_logs/graph_debug_*.log`
- **Server Docs**: `http://127.0.0.1:8123/docs`

### **ğŸ”§ Common Commands**
```bash
# Run comprehensive debug
./debug_local.sh

# Kill all LangGraph processes
pkill -f "langgraph dev"

# Check what's running on port 8123
lsof -i :8123

# Monitor server health
watch -n 5 'curl -s http://127.0.0.1:8123/assistants | head -1'

# Analyze debug logs
grep -E "NODE (START|ERROR|COMPLETE)" debug_logs/graph_debug_*.log

# Check for async issues
grep -E "CancelledError|coroutine.*attribute" debug_logs/debug_session_*.log
```

---

## ğŸ‰ **Success Indicators**

Your LangGraph debug session is successful when:

1. **âœ… Debug script passes** - All 7 phases complete
2. **âœ… Server starts without flags** - No `--allow-blocking` needed
3. **âœ… Full graph execution** - Complete trading analysis
4. **âœ… All nodes visible** - 21+ nodes in LangGraph Studio
5. **âœ… No blocking operations** - Pure async execution
6. **âœ… Comprehensive logging** - Detailed node execution logs
7. **âœ… Error-free execution** - No `CancelledError` or `KeyError`

---

## ğŸ”§ **Troubleshooting FAQ**

### **Q: Debug script fails in Phase 1**
**A:** Check Python installation and virtual environment setup
```bash
python3 --version
which python3
```

### **Q: Import errors in Phase 2**  
**A:** Verify PYTHONPATH and dependencies
```bash
echo $PYTHONPATH
pip list | grep langchain
```

### **Q: LLM test fails in Phase 3**
**A:** Check API key configuration
```bash
echo $OPENAI_API_KEY | head -c 10  # Should show "sk-proj-" or "sk-"
```

### **Q: Server won't start in Phase 4**
**A:** Check port availability and LangGraph CLI
```bash
lsof -i :8123
langgraph --version
```

### **Q: Graph execution incomplete**
**A:** Check debug logs for specific node failures
```bash
grep "NODE ERROR" debug_logs/graph_debug_*.log
```

---

**ğŸ¯ Remember**: The key to successful LangGraph debugging is systematic testing, comprehensive logging, and ensuring full async compatibility throughout your graph. Use the debug script for quick verification and the detailed logs for deep issue analysis! 